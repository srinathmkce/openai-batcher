{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cdb7603",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:26:36.606763Z",
     "start_time": "2024-06-18T14:26:36.603748Z"
    }
   },
   "outputs": [],
   "source": [
    "# ! pip install openai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c59c2ae8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T19:18:21.499090Z",
     "start_time": "2024-07-20T19:18:12.158072Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from openai import OpenAI\n",
    "import getpass\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Image, display\n",
    "from datasets import Dataset, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b067a0bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T19:18:30.626189Z",
     "start_time": "2024-07-20T19:18:29.456526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your OpenAI API key: ········\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25b3c546",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T19:18:32.339894Z",
     "start_time": "2024-07-20T19:18:32.108064Z"
    }
   },
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93124947",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T19:19:02.434911Z",
     "start_time": "2024-07-20T19:18:33.595987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ddb1a2ad8a4f649679696f04a7fe28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"wikimedia/wikipedia\", \"20231101.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "524ff5fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T19:19:23.502832Z",
     "start_time": "2024-07-20T19:19:23.499872Z"
    }
   },
   "outputs": [],
   "source": [
    "categorize_system_prompt = '''\n",
    "Your task is to assess customers article and categorize customer article into one of the following predfined categories:\n",
    "'History', 'Geography', 'Science', 'Technology', 'Mathematics', 'Literature', 'Art', 'Music', 'Film', 'Television', 'Sports', 'Politics', 'Philosophy', 'Religion', 'Sociology', 'Psychology', 'Economics', 'Business', 'Medicine', 'Biology', 'Chemistry', 'Physics', 'Astronomy', 'Environmental Science', 'Engineering', 'Computer Science', 'Linguistics', 'Anthropology', 'Archaeology', 'Education', 'Law', 'Military', 'Architecture', 'Fashion', 'Cuisine', 'Travel', 'Mythology', 'Folklore', 'Biography', 'Mythology', 'Social Issues', 'Human Rights', 'Technology Ethics', 'Climate Change', 'Conservation', 'Urban Studies', 'Demographics', 'Journalism', 'Cryptocurrency', 'Artificial Intelligence'\n",
    "you will output a json object containing the following information:\n",
    "\n",
    "{\n",
    "    categories: string[] // category name based on the article,\n",
    "}\n",
    "\n",
    "Keep category names simple and use only lower case letters.\n",
    "Articles can have only one category.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a736d155",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T19:19:41.336215Z",
     "start_time": "2024-07-20T19:19:41.244026Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_prompt(ids, articles):\n",
    "    tasks = []\n",
    "    token_list = []\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    for index, article in enumerate(articles):\n",
    "        task = {\n",
    "            \"custom_id\": f\"task-{ids[index]}\",\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                # This is what you would have in your Chat Completions API call\n",
    "#                 \"model\": \"gpt-3.5-turbo\",\n",
    "                \"model\": \"gpt-4o-mini\",\n",
    "                \"temperature\": 0.1,\n",
    "                \"response_format\": { \n",
    "                    \"type\": \"json_object\"\n",
    "                },\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": categorize_system_prompt\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": article\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        }\n",
    "\n",
    "        tasks.append(task)\n",
    "        total_tokens = len(encoding.encode(categorize_system_prompt)) + len(encoding.encode(article))\n",
    "        token_list.append(total_tokens)\n",
    "    print(\"Total input tokens: \", sum(token_list))\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3850d303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T19:21:54.087380Z",
     "start_time": "2024-07-20T19:21:54.083812Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"batch\"):\n",
    "    os.mkdir(\"batch\")\n",
    "if not os.path.exists(\"output\"):\n",
    "    os.mkdir(\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69800e95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T19:21:55.770733Z",
     "start_time": "2024-07-20T19:21:55.766556Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_batch_files(file_name, start, end):\n",
    "    with open(file_name, 'w') as file:\n",
    "        for obj in tasks:\n",
    "            file.write(json.dumps(obj) + '\\n')\n",
    "    print(f\"Writing batch to file: {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5763fe8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T19:21:56.126640Z",
     "start_time": "2024-07-20T19:21:56.122534Z"
    }
   },
   "outputs": [],
   "source": [
    "def fetch_results(job_id, output_file_name):\n",
    "    result_file_id = client.batches.retrieve(batch_id=job_id).output_file_id\n",
    "    result = client.files.content(result_file_id).content\n",
    "    result_file_name = f\"output/output_{output_file_name}\"\n",
    "    print(f\"Writing to file: {result_file_name}\")\n",
    "    with open(result_file_name, 'wb') as file:\n",
    "        file.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "580bf5fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T19:21:57.634901Z",
     "start_time": "2024-07-20T19:21:57.630295Z"
    }
   },
   "outputs": [],
   "source": [
    "def wait_until_job_is_finished(job_id, file_name):\n",
    "    while True:\n",
    "        status = client.batches.retrieve(batch_id=job_id).status\n",
    "        print(f\"Job Status: {status}\")\n",
    "        if status == \"failed\" or status == \"error\":\n",
    "            print(f\"Issue with the batch - {file_name}\")\n",
    "            return\n",
    "        elif status == \"completed\":\n",
    "            print(\"Fetching results\")\n",
    "            fetch_results(job_id=job_id, output_file_name=file_name)\n",
    "            return\n",
    "        else:\n",
    "            print(\"Sleeping for 30 seconds\")\n",
    "            time.sleep(30)\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3fafcc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T19:25:56.218291Z",
     "start_time": "2024-07-20T19:21:59.950645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing records from 0 to 199\n",
      "Total input tokens:  71860\n",
      "Writing batch to file: batch\\articles_0_to_200.jsonl\n",
      "FileObject(id='file-MJ0yGmu4SJNTAwP8vTRTYnnb', bytes=355648, created_at=1721503326, filename='articles_0_to_200.jsonl', object='file', purpose='batch', status='processed', status_details=None)\n",
      "Job Status: validating\n",
      "Sleeping for 30 seconds\n",
      "Job Status: in_progress\n",
      "Sleeping for 30 seconds\n",
      "Job Status: completed\n",
      "Fetching results\n",
      "Writing to file: output/output_articles_0_to_200.jsonl\n",
      "\n",
      "\n",
      "\n",
      "Processing records from 200 to 399\n",
      "Total input tokens:  68164\n",
      "Writing batch to file: batch\\articles_200_to_400.jsonl\n",
      "FileObject(id='file-nwGdlYJJVZLCNt4eHsEOelWu', bytes=339291, created_at=1721503391, filename='articles_200_to_400.jsonl', object='file', purpose='batch', status='processed', status_details=None)\n",
      "Job Status: validating\n",
      "Sleeping for 30 seconds\n",
      "Job Status: completed\n",
      "Fetching results\n",
      "Writing to file: output/output_articles_200_to_400.jsonl\n",
      "\n",
      "\n",
      "\n",
      "Processing records from 400 to 599\n",
      "Total input tokens:  69345\n",
      "Writing batch to file: batch\\articles_400_to_600.jsonl\n",
      "FileObject(id='file-MgXEO4tZaJbCjgBVc7fcQZOt', bytes=335529, created_at=1721503424, filename='articles_400_to_600.jsonl', object='file', purpose='batch', status='processed', status_details=None)\n",
      "Job Status: validating\n",
      "Sleeping for 30 seconds\n",
      "Job Status: finalizing\n",
      "Sleeping for 30 seconds\n",
      "Job Status: completed\n",
      "Fetching results\n",
      "Writing to file: output/output_articles_400_to_600.jsonl\n",
      "\n",
      "\n",
      "\n",
      "Processing records from 600 to 799\n",
      "Total input tokens:  70018\n",
      "Writing batch to file: batch\\articles_600_to_800.jsonl\n",
      "FileObject(id='file-TbnVnElAHFNec1TAp2vN6Cw9', bytes=344302, created_at=1721503488, filename='articles_600_to_800.jsonl', object='file', purpose='batch', status='processed', status_details=None)\n",
      "Job Status: validating\n",
      "Sleeping for 30 seconds\n",
      "Job Status: completed\n",
      "Fetching results\n",
      "Writing to file: output/output_articles_600_to_800.jsonl\n",
      "\n",
      "\n",
      "\n",
      "Processing records from 800 to 999\n",
      "Total input tokens:  68940\n",
      "Writing batch to file: batch\\articles_800_to_1000.jsonl\n",
      "FileObject(id='file-KIOW5Wofmx07gKV0py6wuUJf', bytes=342389, created_at=1721503523, filename='articles_800_to_1000.jsonl', object='file', purpose='batch', status='processed', status_details=None)\n",
      "Job Status: validating\n",
      "Sleeping for 30 seconds\n",
      "Job Status: completed\n",
      "Fetching results\n",
      "Writing to file: output/output_articles_800_to_1000.jsonl\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "START_INDEX = 0\n",
    "END_INDEX = 1000\n",
    "BATCH_SIZE = 200\n",
    "INPUT_DIR = \"batch\"\n",
    "\n",
    "for start in range(START_INDEX, END_INDEX, BATCH_SIZE):\n",
    "    end = min(start + BATCH_SIZE, END_INDEX)\n",
    "    # Process the records from 'start' to 'end'\n",
    "    print(f\"Processing records from {start} to {end-1}\")\n",
    "    file_name = f\"articles_{start}_to_{end}.jsonl\"\n",
    "    input_file_path = os.path.join(INPUT_DIR, file_name)\n",
    "    \n",
    "    # Gather the articles\n",
    "    articles = dataset[\"train\"][start:end][\"text\"]\n",
    "    articles = [x.split(\"\\n\")[0] for x in articles]\n",
    "    ids = dataset[\"train\"][start:end][\"id\"]\n",
    "    \n",
    "    # Generate prompt\n",
    "    tasks = create_prompt(ids=ids, articles=articles)\n",
    "    \n",
    "    # Create batch files\n",
    "    create_batch_files(file_name=input_file_path, start=start, end=end)\n",
    "    \n",
    "    # Upload and start the batch\n",
    "    batch_file = client.files.create(file=open(input_file_path, \"rb\"), purpose=\"batch\")\n",
    "    print(batch_file)\n",
    "\n",
    "    #Start the batch execution\n",
    "    batch_job = client.batches.create(\n",
    "      input_file_id=batch_file.id,\n",
    "      endpoint=\"/v1/chat/completions\",\n",
    "      completion_window=\"24h\"\n",
    "    )\n",
    "    \n",
    "    job_id = batch_job.id\n",
    "    \n",
    "    # Code to wait till the status is complete\n",
    "    wait_until_job_is_finished(job_id=job_id, file_name=file_name)\n",
    "#     for _ in range(40):\n",
    "#         status = client.batches.retrieve(batch_id=job_id).status\n",
    "#         print(f\"Job Status: {status}\")\n",
    "#         if status == \"failed\":\n",
    "#             print(f\"Issue with the batch - {file_name}\")\n",
    "#             break\n",
    "#         if status != \"completed\":\n",
    "#             print(\"Sleeping for 30 seconds\")\n",
    "#             time.sleep(30)\n",
    "#         else:\n",
    "#             print(\"Fetching results\")\n",
    "#             fetch_results(job_id=job_id, output_file_name=file_name)\n",
    "#             break\n",
    "#     else:\n",
    "#         raise TimeoutError(\"Batch processing did not complete after 300 seconds\")\n",
    "    \n",
    "    print(\"\\n\\n\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5d780f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T19:27:23.372823Z",
     "start_time": "2024-07-20T19:27:22.794730Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 492.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n",
      "       id      category\n",
      "0      12      politics\n",
      "1      39       science\n",
      "2     290   linguistics\n",
      "3     303     geography\n",
      "4     305     mythology\n",
      "..    ...           ...\n",
      "995  2448  human rights\n",
      "996  2452              \n",
      "997  2457       biology\n",
      "998  2459       history\n",
      "999  2460           sex\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "Total number of Input tokens:  351913\n",
      "Total number of Output tokens:  9453\n",
      "0.190136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Postprocessing\n",
    "OUTPUT_DIR = \"output\"\n",
    "\n",
    "def post_processing(output_dir):\n",
    "    result = []\n",
    "    prompt_tokens = 0\n",
    "    completion_tokens = 0\n",
    "    output_files = os.listdir(output_dir)\n",
    "    for output_file in tqdm(output_files):\n",
    "        with open(os.path.join(OUTPUT_DIR,output_file), 'r') as file:\n",
    "            for line in file:\n",
    "                json_object = json.loads(line.strip())\n",
    "                task_id = json_object['custom_id']\n",
    "                index = task_id.split('-')[-1]\n",
    "                try:\n",
    "                    category_str = json_object['response']['body']['choices'][0]['message']['content']\n",
    "                    category = json.loads(category_str)[\"categories\"]\n",
    "                    category = category[0] if category else \"\"\n",
    "                    prompt_tokens += json_object['response']['body']['usage']['prompt_tokens']\n",
    "                    completion_tokens += json_object['response']['body']['usage']['completion_tokens']\n",
    "                except Exception as e:\n",
    "                    print(json_object)\n",
    "                    raise Exception(\"Error\")\n",
    "                result.append((index, category))\n",
    "    return pd.DataFrame(result, columns=[\"id\", \"category\"]), prompt_tokens, completion_tokens\n",
    "    \n",
    "output_df, prompt_tokens, completion_tokens = post_processing(OUTPUT_DIR)\n",
    "\n",
    "print(output_df.shape)\n",
    "print(output_df)\n",
    "print(\"Total number of Input tokens: \", prompt_tokens)\n",
    "print(\"Total number of Output tokens: \", completion_tokens)\n",
    "\n",
    "estimated_cost = ((prompt_tokens * 0.5) / 1000000) + ((completion_tokens * 1.5) / 1000000)\n",
    "print(estimated_cost)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2897479",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T14:11:18.807864Z",
     "start_time": "2024-06-24T14:11:18.804756Z"
    }
   },
   "outputs": [],
   "source": [
    "# ((3449532 * 5) / 1000000) + ((104038 * 15) / 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7cc156fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T14:11:20.835451Z",
     "start_time": "2024-06-24T14:11:20.832426Z"
    }
   },
   "outputs": [],
   "source": [
    "# ((3449532 * 10) / 1000000) + ((104038 * 30) / 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e66f0b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T14:04:46.227834Z",
     "start_time": "2024-06-24T14:04:46.188453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geography': 4238,\n",
       " 'history': 3822,\n",
       " 'sports': 3648,\n",
       " 'music': 2875,\n",
       " 'politics': 1616,\n",
       " 'film': 1038,\n",
       " 'literature': 957,\n",
       " 'television': 935,\n",
       " 'biology': 906,\n",
       " 'technology': 725,\n",
       " 'religion': 706,\n",
       " 'business': 548,\n",
       " 'education': 537,\n",
       " 'biography': 472,\n",
       " 'medicine': 452,\n",
       " 'law': 423,\n",
       " 'art': 411,\n",
       " 'architecture': 403,\n",
       " 'engineering': 344,\n",
       " 'military': 329,\n",
       " 'mathematics': 327,\n",
       " 'journalism': 306,\n",
       " 'chemistry': 275,\n",
       " 'linguistics': 251,\n",
       " 'mythology': 212,\n",
       " 'travel': 201,\n",
       " 'economics': 195,\n",
       " 'computer science': 194,\n",
       " 'environmental science': 187,\n",
       " 'cuisine': 163,\n",
       " 'astronomy': 162,\n",
       " 'sociology': 161,\n",
       " 'video games': 145,\n",
       " 'physics': 142,\n",
       " 'philosophy': 141,\n",
       " 'anthropology': 122,\n",
       " 'psychology': 106,\n",
       " 'social issues': 79,\n",
       " 'archaeology': 78,\n",
       " 'comics': 65,\n",
       " 'transportation': 65,\n",
       " 'fashion': 64,\n",
       " 'games': 55,\n",
       " '': 52,\n",
       " 'folklore': 48,\n",
       " 'science': 42,\n",
       " 'agriculture': 41,\n",
       " 'acronyms': 40,\n",
       " 'automotive': 34,\n",
       " 'geology': 33,\n",
       " 'true crime': 31,\n",
       " 'botany': 30,\n",
       " 'acronym': 28,\n",
       " 'anatomy': 28,\n",
       " 'theatre': 26,\n",
       " 'language': 25,\n",
       " 'space': 25,\n",
       " 'demographics': 18,\n",
       " 'crime': 18,\n",
       " 'media': 16,\n",
       " 'performing arts': 16,\n",
       " 'radio': 16,\n",
       " 'dance': 12,\n",
       " 'food': 12,\n",
       " 'urban studies': 12,\n",
       " 'board games': 11,\n",
       " 'comedy': 10,\n",
       " 'meteorology': 9,\n",
       " 'statistics': 9,\n",
       " 'human rights': 9,\n",
       " 'climate change': 9,\n",
       " 'political science': 9,\n",
       " 'zoology': 9,\n",
       " 'aviation': 8,\n",
       " 'conservation': 8,\n",
       " 'culture': 8,\n",
       " 'ethics': 8,\n",
       " 'artificial intelligence': 7,\n",
       " 'photography': 7,\n",
       " 'animals': 7,\n",
       " 'martial arts': 6,\n",
       " 'forensics': 5,\n",
       " 'neuroscience': 5,\n",
       " 'culinary': 5,\n",
       " 'amusement park': 5,\n",
       " 'terrorism': 5,\n",
       " 'fiction': 5,\n",
       " 'space exploration': 5,\n",
       " 'library': 5,\n",
       " 'entertainment': 5,\n",
       " 'firearms': 5,\n",
       " 'toys': 5,\n",
       " 'technology ethics': 5,\n",
       " 'arts': 4,\n",
       " 'theater': 4,\n",
       " 'transport': 4,\n",
       " 'events': 4,\n",
       " 'animal rights': 4,\n",
       " 'biochemistry': 4,\n",
       " 'crafts': 4,\n",
       " 'government': 3,\n",
       " 'theology': 3,\n",
       " 'chess': 3,\n",
       " 'hobbies': 3,\n",
       " 'philanthropy': 3,\n",
       " 'communication': 2,\n",
       " 'magazine': 2,\n",
       " 'veterinary medicine': 2,\n",
       " 'paranormal': 2,\n",
       " 'cryptography': 2,\n",
       " 'exploration': 2,\n",
       " 'cryptocurrency': 2,\n",
       " 'marine science': 2,\n",
       " 'oceanography': 2,\n",
       " 'library science': 2,\n",
       " 'anime': 2,\n",
       " 'pop culture': 2,\n",
       " 'publishing': 2,\n",
       " 'atmospheric science': 2,\n",
       " 'design': 2,\n",
       " 'typography': 1,\n",
       " 'ethnomusicology': 1,\n",
       " 'earth and atmospheric science': 1,\n",
       " 'food technology': 1,\n",
       " 'household': 1,\n",
       " 'space technology': 1,\n",
       " 'food and drink': 1,\n",
       " 'information': 1,\n",
       " 'activism': 1,\n",
       " 'advertising': 1,\n",
       " 'ufology': 1,\n",
       " 'magic': 1,\n",
       " 'community': 1,\n",
       " 'science fiction': 1,\n",
       " 'numismatics': 1,\n",
       " 'space colonization': 1,\n",
       " 'card games': 1,\n",
       " 'espionage': 1,\n",
       " 'nutrition': 1,\n",
       " 'collectibles': 1,\n",
       " 'food processing': 1,\n",
       " 'uncategorized': 1,\n",
       " 'mining': 1,\n",
       " 'occult': 1,\n",
       " 'pseudoscience': 1,\n",
       " 'political': 1,\n",
       " 'humor': 1,\n",
       " 'lgbtq': 1,\n",
       " 'materials science': 1,\n",
       " 'craft': 1,\n",
       " 'geometry': 1,\n",
       " 'poetry': 1,\n",
       " 'astrology': 1,\n",
       " 'paleontology': 1,\n",
       " 'internet': 1,\n",
       " 'outdoor activities': 1,\n",
       " 'charity': 1,\n",
       " 'marine biology': 1,\n",
       " 'slang': 1,\n",
       " 'manga': 1,\n",
       " 'celebrity': 1,\n",
       " 'logic': 1,\n",
       " 'gambling': 1,\n",
       " 'self-help': 1,\n",
       " 'antiques': 1,\n",
       " 'finance': 1,\n",
       " 'gender studies': 1,\n",
       " 'beauty': 1,\n",
       " 'conspiracy': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.category.value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2d3bf28d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T16:41:09.220669Z",
     "start_time": "2024-06-20T16:41:09.048504Z"
    }
   },
   "outputs": [],
   "source": [
    "# output_df.to_csv(\"articles_10000_to_30000.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d48b339",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T14:11:26.405601Z",
     "start_time": "2024-06-24T14:11:26.402261Z"
    }
   },
   "outputs": [],
   "source": [
    "# output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffce714c",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ea6ac05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T14:06:48.147575Z",
     "start_time": "2024-06-24T14:06:47.552469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = dataset[\"train\"][:30000][\"text\"]\n",
    "# articles = [x.split(\"\\n\")[0] for x in articles]\n",
    "ids = dataset[\"train\"][:30000][\"id\"]\n",
    "\n",
    "input_df = pd.DataFrame({\"id\": ids, \"article\": articles})\n",
    "input_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f65fbfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T14:06:52.112349Z",
     "start_time": "2024-06-24T14:06:52.083971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_article_df = pd.merge(left=input_df, right=output_df, how=\"inner\", on=\"id\")\n",
    "cat_article_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c654488",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T14:06:54.959999Z",
     "start_time": "2024-06-24T14:06:54.952529Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>Anarchism is a political philosophy and moveme...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>Albedo (; ) is the fraction of sunlight that i...</td>\n",
       "      <td>physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>290</td>\n",
       "      <td>A, or a, is the first letter and the first vow...</td>\n",
       "      <td>linguistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>303</td>\n",
       "      <td>Alabama () is a state in the Southeastern regi...</td>\n",
       "      <td>geography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>305</td>\n",
       "      <td>In Greek mythology, Achilles ( ) or Achilleus ...</td>\n",
       "      <td>mythology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                            article     category\n",
       "0   12  Anarchism is a political philosophy and moveme...     politics\n",
       "1   39  Albedo (; ) is the fraction of sunlight that i...      physics\n",
       "2  290  A, or a, is the first letter and the first vow...  linguistics\n",
       "3  303  Alabama () is a state in the Southeastern regi...    geography\n",
       "4  305  In Greek mythology, Achilles ( ) or Achilleus ...    mythology"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_article_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c4d94d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T14:07:00.490957Z",
     "start_time": "2024-06-24T14:06:57.664427Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_article_df.to_csv(\"articles_0_to_30000.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a3cabc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
